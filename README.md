| NAME                     | PROMPT                  | DESCRIPTION               | EXAMPLE                                         |
|--------------------------|-------------------------|---------------------------|-------------------------------------------------|
| app.yaml                 | Generate a Kubernetes Pod manifest in YAML format. The Pod should be named 'app' with labels 'app: demo' and 'run: demo'. It should contain a single container using the image 'gcr.io/k8s-k3s/demo:v1.0.0'. Name the container 'app' and expose it on container port 8000 with the name 'http'.     | This Kubernetes Pod manifest defines a Pod named 'app' with specific labels for identification. It is configured to run a single container using the 'gcr.io/k8s-k3s/demo:v1.0.0' image. The container, also named 'app', exposes port 8000 for network communication, facilitating access to the application running inside it. This setup is typically used for running a standalone instance of a microservice or application in a Kubernetes environment."  | [Link to app.yaml](yaml/app.yaml)               |
| app-livenessProbe.yaml   | Create a Kubernetes Pod manifest in YAML format named 'app-livenessprob' within the 'demo' namespace. The Pod should have a single container using the 'gcr.io/k8s-k3s/demo:v1.0.0' image, named 'app'. Include a liveness probe with an HTTP GET request to the root path on port 8000, starting after an initial delay of 5 seconds, timing out after 1 second, and repeating every 10 seconds. The probe should have a failure threshold of 3. Additionally, expose the container's port 8080 with the name 'http'.      | This Kubernetes Pod manifest, named 'app-livenessprob', is designed for the 'demo' namespace and is tailored for maintaining high availability and healthy operation. It specifies a Pod running a single container based on the 'gcr.io/k8s-k3s/demo:v1.0.0' image. The liveness probe included in the container's configuration is crucial for ensuring that the application is running as expected. It performs an HTTP GET request to the application's root path on port 8000. The probe starts after an initial delay of 5 seconds, allowing the application sufficient time to start up. It has a timeout of 1 second for each probe and checks the application's health every 10 seconds. If the probe fails 3 consecutive times (as indicated by the 'failureThreshold'), Kubernetes will take appropriate action, like restarting the container. This helps in automatically handling scenarios where the application becomes unresponsive. The container also exposes port 8080 for external access, labeled as 'http', to interact with the application hosted inside.   | [Link to app-livenessProbe.yaml](yaml/app-livenessProbe.yaml) |
| app-readinessProbe.yaml  | Create a Kubernetes Pod manifest in YAML format named 'app-readinessprob'. The Pod should contain a single container using the image 'gcr.io/k8s-k3s/demo:v2.0.0' with the name 'app'. Configure both liveness and readiness probes. The liveness probe should perform an HTTP GET request to the root path on port 8000, with an initial delay of 5 seconds, a timeout of 1 second, repeating every 10 seconds, and a failure threshold of 3. The readiness probe should target the '/ready' path on port 8000, starting immediately, checking every 2 seconds, and requiring a single successful check to pass. Expose container port 8000 with the name 'http'.      | This Kubernetes Pod manifest, named 'app-readinessprob', is designed to ensure that the containerized application is both alive and ready to serve traffic. It deploys a single container based on the 'gcr.io/k8s-k3s/demo:v2.0.0' image. The liveness probe is configured to check the applicationâ€™s health by sending an HTTP GET request to the root path on port 8000. It waits for 5 seconds before starting the checks to allow the application to initialize, repeating the checks every 10 seconds with a 1-second timeout. If the liveness probe fails 3 times consecutively, Kubernetes will restart the container. In addition to the liveness probe, a readiness probe is set up to ensure the application is ready to handle traffic. This probe hits the '/ready' endpoint, starting immediately without any delay, checking every 2 seconds. The application is considered ready to receive traffic after one successful check, as indicated by the 'successThreshold'. This setup helps in managing the traffic to the container, ensuring it only receives requests when fully operational. The container also exposes port 8000, named 'http', to facilitate network communication with the application.   | [Link to app-readinessProbe.yaml](yaml/app-readinessProbe.yaml) |
| app-volumeMounts.yaml    | Construct a Kubernetes Pod manifest named 'app-volume' in YAML format. This Pod should run a single container using the image 'gcr.io/kuar-demo/kuard-amd64:1', named 'app'. Configure the container with both liveness and readiness probes. The liveness probe should check the '/healthy' endpoint on port 8080, initiating after 5 seconds with a 1-second timeout, repeating every 10 seconds, and having a failure threshold of 3. The readiness probe should target '/ready' on port 8080, starting immediately, repeating every 2 seconds, with a failure threshold of 3 and needing only one successful check to pass. Additionally, the container should expose port 8080 as 'http'. Include a volume mount at '/data' in the container, linked to a hostPath volume named 'data' located at '/var/lib/app'.     | This Kubernetes Pod manifest, named 'app-volume', is carefully crafted for deploying a containerized application with specific health checks and storage requirements. It features a single container derived from the 'gcr.io/kuar-demo/kuard-amd64:1' image, aptly named 'app'. Critical to maintaining the container's health, the liveness probe is set to periodically verify the application's health by accessing the '/healthy' path on port 8080. This probe starts 5 seconds after the container's initiation, allowing for sufficient boot-up time, and runs every 10 seconds. The readiness probe ensures the container is prepared to handle traffic by checking the '/ready' endpoint on port 8080, starting immediately after the container starts and running every 2 seconds. The container is deemed ready for traffic after one successful check. For networking, the container opens port 8080, labeled 'http', facilitating external communication with the service.   | [Link to app-volumeMounts.yaml](yaml/app-volumeMounts.yaml) |
| app-cronjob.yaml         | Create a YAML manifest for a Kubernetes CronJob named 'app-cronjob'. Set it to run on a schedule of every 5 minutes. The CronJob should execute a Job that runs a container with the name 'hello' using the 'bash' image. The container should execute the command 'echo "Hello world"'. Ensure that the restart policy is set to 'OnFailure'.      | This manifest defines a Kubernetes CronJob resource, named 'app-cronjob', responsible for executing a scheduled task at regular intervals. The specified schedule '*/5 * * * *' dictates that the job should be triggered every 5 minutes. Within the CronJob, a Job template is specified. This Job template outlines the execution details of a single Pod. The Pod runs a container named 'hello', which is based on the 'bash' image. The primary function of this container is to execute a simple bash command: 'echo "Hello world"', which outputs the phrase 'Hello world' to the console. This is an example of a CronJob that could be used for basic recurring tasks or as a template for more complex scheduled jobs.   | [Link to app-cronjob.yaml](yaml/app-cronjob.yaml) |
| app-job.yaml             | Write a YAML manifest for a Kubernetes Job named 'app-job-rsync'. The Job should execute a container named 'init' using the image 'google/cloud-sdk:275.0.0-alpine'. The container should run a command to synchronize data from a Google Cloud Storage bucket 'gs://glow-sportradar/' to a mounted directory '/data/input'. Include a volume named 'data-input' which uses a GCE persistent disk named 'glow-data-disk-200' with the filesystem type 'ext4'. Set the restart policy to 'Never' and the backoff limit to 0."      | This Kubernetes Job manifest, named 'app-job-rsync', is designed to perform a one-time data synchronization task. It defines a Job resource that initiates a Pod to run a specific task - in this case, data synchronization using Google Cloud SDK tools. The Job creates a Pod with a single container named 'init'. This container is based on the 'google/cloud-sdk:275.0.0-alpine' image, which is a lightweight version of the Google Cloud SDK. The primary task of this container is to execute the gsutil command, which is a part of the Google Cloud SDK, to synchronize data from the specified Google Cloud Storage bucket 'gs://glow-sportradar/' to a local directory in the Pod, '/data/input'. To facilitate this operation, the Pod is configured with a volume named 'data-input'. This volume is backed by a GCE (Google Compute Engine) persistent disk named 'glow-data-disk-200', which uses the 'ext4' filesystem. This setup ensures that the data synchronized from the Cloud Storage bucket is stored on a persistent disk, making it available for further processing or usage even after the Job completes. The Job is configured with a 'Never' restart policy, meaning that the Pod will not be restarted once it completes its task or if it fails. Additionally, the 'backoffLimit' is set to 0, which implies that Kubernetes will not attempt to retry the Job if it fails on the first attempt. This configuration is typical for tasks that are intended to be run manually or where automatic retries are not desirable.   | [Link to app-job.yaml](yaml/app-job.yaml)       |
| app-multicontainer.yaml  | Create a Kubernetes Pod manifest in YAML format named 'app-multi-containers'. The Pod should consist of two containers. The first container, named '1st', should use the 'nginx' image and mount a volume named 'html' at '/usr/share/nginx/html'. The second container, named '2nd', should use the 'debian' image and mount the same 'html' volume at '/html'. The second container should continuously write the current date to a file named 'index.html' in its mount path every second.      | This Kubernetes Pod manifest, named 'app-multi-containers', orchestrates a multi-container Pod, each serving a unique role, yet working together through shared storage. The first container, labeled '1st', is based on the 'nginx' image, a popular web server. It is configured to serve content from the '/usr/share/nginx/html' directory, which is mapped to a shared volume named 'html'. This volume is defined as an 'emptyDir', meaning it will be ephemeral and created when the Pod is assigned to a node, and it will exist as long as the Pod runs on that node. The second container, named '2nd', is built from the 'debian' image, providing a general-purpose Linux environment. This container mounts the same 'html' volume to its local '/html' directory. The primary function of this container is to update an 'index.html' file in this shared volume with the current date, appending a new entry every second. This is achieved by executing a shell command in a loop. The combination of these two containers demonstrates a common pattern in Kubernetes of using sidecar containers - where one container is the main actor (in this case, the 'nginx' container serving web content) and the other plays a supporting role (the 'debian' container, updating the content). The shared volume 'html' acts as the communication bridge between these two containers, allowing the 'nginx' container to serve dynamically updated content generated by the 'debian' container."   | [Link to app-multicontainer.yaml](yaml/app-multicontainer.yaml) |
| app-resources.yaml       | Create a YAML manifest for a Kubernetes Pod named 'app-resource'. The Pod should contain a single container using the image 'gcr.io/kuar-demo/kuard-amd64:1', named 'app'. Configure the container with both liveness and readiness probes targeting '/healthy' and '/ready' paths respectively on port 8080. The liveness probe should have an initial delay of 5 seconds, timeout of 1 second, period of 10 seconds, and a failure threshold of 3. The readiness probe should start immediately, check every 2 seconds, have a failure threshold of 3, and require one successful check to pass. The container should expose port 8080 as 'http'. Define resource requests for 100m CPU and 128Mi memory, and limits of 100m CPU and 256Mi memory.      | This Kubernetes Pod manifest, named 'app-resource', deploys a single container from 'gcr.io/kuar-demo/kuard-amd64:1'. It includes liveness and readiness probes to ensure service health and readiness, targeting '/healthy' and '/ready' on port 8080, respectively. The container exposes port 8080 and is configured with resource constraints: it requests 100m CPU and 128Mi memory, with limits set to 100m CPU and 256Mi memory. This setup ensures efficient resource utilization and maintains the application's stability and availability within the Kubernetes environment.   | [Link to app-resources.yaml](yaml/app-resources.yaml) |
| app-secret-env.yaml      | Create a YAML manifest for a Kubernetes Pod named 'app-secret-env'. The Pod should have a single container named 'mycontainer' using the 'redis' image. Configure the container to use environment variables 'SECRET_USERNAME' and 'SECRET_PASSWORD', which should be sourced from a Kubernetes Secret named 'mysecret1' with keys 'username' and 'password', respectively. Set the restart policy of the Pod to 'Never'.      | This Kubernetes Pod, named 'app-secret-env', contains a single container 'mycontainer' running the 'redis' image. It uses environment variables sourced from a Kubernetes Secret 'mysecret1' for 'SECRET_USERNAME' and 'SECRET_PASSWORD'. The Pod has a 'Never' restart policy.   | [Link to app-secret-env.yaml](yaml/app-secret-env.yaml) |
